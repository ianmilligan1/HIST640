---
title: "Module Four: Thinking Like a Machine"
linkTitle: "4: Thinking Like a Machine: Algorithmic Bias and Machine Learning"
weight: 4
description: >
  How can we think like a machine? How do algorithms affect historical research?
---

{{< figure src="robot.jpg" height="5" class="text-center">}}

{{% pageinfo %}}
**Admit it**: almost everything you learn you learn via Google. How does it shape your worldview?

This week, we do two main things:

* An introduction to the basics of artificial intelligence and machine learning. What are they? Why should historians care?
* An introduction to algorithmic bias and critical approaches to this field. How do machines reflect the biases that we inscribe on them?

{{% /pageinfo %}}

## Readings for this Week

{{< youtube 5bMBKlRhZnQ >}}
_A short video introduction to some of these ideas. Looking forward to our seminar discussion about this as always!_

Please consider the **Putnam reading** from the last module to be part of this, as we'll touch on this as an example of how bias plays out in historical research. Many of these readings are from outside of the field of history, but they will help explain the field to you and we'll do the application part in our class discussion (see below).

* Safiya Noble, “A Society, Searching,” from _Algorithms of Oppression: How Search Engines Reinforce Racism_ (New York: NYU Press, 2018). I’ll e-mail you this chapter (fair dealing).
* Cathy O’Neill, “What is a Model?” from _Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy_ (New York: Penguin/Random House, 2016). I’ll e-mail you this chapter (fair dealing).
* Ted Underwood, "Why an Age of Machine Learning Needs the Humanities," _Public Books_, 2018. <https://www.publicbooks.org/why-an-age-of-machine-learning-needs-the-humanities/>
* Nicol Turner Lee, Paul Resnick, and Genie Barton, "Algorithmic bias detection and mitigation: Best practices and policies to reduce consumer harms," _Brooking Institute Report_, 2019. <https://www.brookings.edu/research/algorithmic-bias-detection-and-mitigation-best-practices-and-policies-to-reduce-consumer-harms/>

## Our Discussion for this Week

In advance of the class, think about the following major prompt:

>Think of your last substantive research project. Could algorithmic bias or digitization bias have influenced this work? If so, how? If not, why not? What would you change in the future to avoid these issues?

Also make sure you have a sense of what machine learning is, what algorithmic bias is, and how these key forces work. 

See you all in class!

## Want to Meet with Me?

As always, you can book a 30-minute meeting with me via Calendly. Use this link [here](https://calendly.com/i2millig/30min). If there are no times that are available, just send me an [email](mailto:i2millig@uwaterloo.ca) and we can work something out. 

This will create a Microsoft Teams appointment. The URL for the Teams link will be in the calendar invitation e-mailed to you.